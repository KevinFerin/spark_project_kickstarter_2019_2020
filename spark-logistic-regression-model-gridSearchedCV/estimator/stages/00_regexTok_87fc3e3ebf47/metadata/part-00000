{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1572357326039,"sparkVersion":"2.4.4","uid":"regexTok_87fc3e3ebf47","paramMap":{"gaps":true,"outputCol":"tokens","inputCol":"text","pattern":"\\W+"},"defaultParamMap":{"minTokenLength":1,"gaps":true,"toLowercase":true,"outputCol":"regexTok_87fc3e3ebf47__output","pattern":"\\s+"}}
